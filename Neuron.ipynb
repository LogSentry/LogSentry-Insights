{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# gonna creat a vir env cuz why not//// i dont want to mess up my system\n",
    "\n",
    "# Create a virtual environment\n",
    "subprocess.check_call([sys.executable, \"-m\", \"venv\", \"myenv\"])\n",
    "\n",
    "# Activate the virtual environment\n",
    "if sys.platform.startswith('win'):\n",
    "    activate_script = \"myenv\\\\Scripts\\\\activate\"\n",
    "else:\n",
    "    activate_script = \"source myenv/bin/activate\"\n",
    "subprocess.check_call(activate_script, shell=True)\n",
    "\n",
    "# Install numpy\n",
    "subprocess.check_call([\"pip\", \"install\", \"numpy\"])\n",
    "\n",
    "# Install tools for multi-threading and multi-core processing\n",
    "subprocess.check_call([\"pip\", \"install\", \"threadpool\", \"multiprocess\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#first neuron implimetaion of neron funtion\n",
    "class Neuron:\n",
    "    def __init__(self, num_inputs):\n",
    "        # Initialize weights randomly\n",
    "        self.weights = np.random.rand(num_inputs)\n",
    "        # Initialize bias randomly\n",
    "        self.bias = np.random.rand()\n",
    "    \n",
    "    def frontProp(self, input):\n",
    "        # Calculate the weighted sum of inputs... it first multiplies each input by its weight and then sums them up\n",
    "        weighted_sum = np.dot(input, self.weights) + self.bias\n",
    "        # Apply activation function (e.g., sigmoid)\n",
    "        activation = self.sigmoid(weighted_sum)\n",
    "        return activation\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7690480920224001\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([0.5, 0.3, 0.8]) \n",
    "neuron = Neuron(num_inputs=3)  # Create an instance of the Neuron class with 3 input neurons\n",
    "activation = neuron.frontProp(inputs)  # Activate the neuron with the given inputs\n",
    "print(activation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# secind neuron implimetaion of neron funtion with teh bality to take 2 dimental inputs\n",
    "class neuron2Col:\n",
    "    def __init__(self, inputs):\n",
    "        # Ensure inputs is a 2D array\n",
    "        if inputs.ndim == 1:\n",
    "            inputs = inputs.reshape(1, -1)\n",
    "        \n",
    "        # Initialize weights randomly\n",
    "        self.weights = np.random.rand(inputs.shape[1])\n",
    "        self.inputs = inputs\n",
    "        # Initialize bias randomly\n",
    "        self.bias = np.random.rand()\n",
    "    \n",
    "    def frontProp(self):\n",
    "        # Get the inputs to a variable\n",
    "        inputs = self.inputs\n",
    "\n",
    "        # Check if inputs is one-dimensional\n",
    "        if inputs.ndim == 1:\n",
    "            # Reshape inputs to be two-dimensional\n",
    "            inputs = inputs.reshape(1, -1)\n",
    "        \n",
    "        # Calculate the weighted sum of inputs\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "\n",
    "        # Apply activation function \n",
    "        activation = self.sigmoid(weighted_sum)\n",
    "        \n",
    "        return activation\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: [0.84796836 0.88687942]\n",
      "Error: [0.00230096 0.23705157]\n"
     ]
    }
   ],
   "source": [
    "# Test the neuron\n",
    "inputs = np.array([[1, 0.5, 0.3, 0.8], [0.2, 0.5,0.8, 0.4]])\n",
    "neuron = neuron2Col(inputs)\n",
    "activation = neuron.frontProp()\n",
    "print(\"Activation:\", activation)\n",
    "# now clauclate hoe far off the activation is from the target\n",
    "# Calculate the error\n",
    "target = np.array([0.8, 0.4])\n",
    "error = np.square(target - activation) # square error funtion is used to calculate the error since the diffrence can be so small \n",
    "print(\"Error:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class backfrontkiller: \n",
    "    def __init__(self, features, labels, lr):\n",
    "        print(\"backfrontkiller is created\")\n",
    "\n",
    "        # Set values for training\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.lr = lr\n",
    "        self.weights = np.random.rand(features.shape[1])  # Initialize weights based on feature count\n",
    "        self.bias = np.random.rand()\n",
    "\n",
    "    def frontProp(self, inputs):\n",
    "        # Calculate the weighted sum of inputs\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        # Apply activation function\n",
    "        pred = self.sigmoid(weighted_sum)\n",
    "        return pred\n",
    "    \n",
    "    def backProp(self, inputs, target, pred):\n",
    "        error = self.mse(target, pred)\n",
    "        d_weights = self.lr * self.mse_derivative(target, pred) * self.sigmoid_derivative(pred) * inputs\n",
    "        d_bias = self.lr * self.mse_derivative(target, pred) * self.sigmoid_derivative(pred)\n",
    "        return d_weights, d_bias\n",
    "\n",
    "    def train(self, epochs): \n",
    "        for e in range(epochs):\n",
    "            for i in range(self.features.shape[0]):\n",
    "                inputs = self.features[i]  # Use the entire row as input\n",
    "                target = self.labels[i]  # Corresponding label\n",
    "                pred = self.frontProp(inputs)\n",
    "                d_weights, d_bias = self.backProp(inputs, target, pred)\n",
    "                self.weights -= d_weights\n",
    "                self.bias -= d_bias\n",
    "\n",
    "    def predict(self, features):\n",
    "        predictions = []\n",
    "        for i in range(features.shape[0]):\n",
    "            inputs = features[i]  # Use the entire row as input\n",
    "            pred = self.frontProp(inputs)\n",
    "            predictions.append(pred)\n",
    "        return predictions  # Return predictions\n",
    "            \n",
    "    # Helper functions\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    def mse(self, target, activation):\n",
    "        return np.square(target - activation)\n",
    "    def mse_derivative(self, target, activation):\n",
    "        return 2 * (activation - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backfrontkiller is created\n",
      "\n",
      "Model accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#_________________ GENRATING SAMPLE DATA _______________________________#\n",
    "\n",
    "\n",
    "# Step 1: Generate random data for training\n",
    "np.random.seed(42)  # for reproducibility\n",
    "n_samples = 1000\n",
    "n_features = 3\n",
    "\n",
    "# Generate random features\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Generate target values (let's say it's a binary classification problem)\n",
    "# We'll use a simple rule: if the sum of features is positive, target is 1, else 0\n",
    "y = (X.sum(axis=1) > 0).astype(int)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "feature_cols = ['feature1', 'feature2', 'feature3']\n",
    "data = pd.DataFrame(X, columns=feature_cols)\n",
    "data['target'] = y\n",
    "\n",
    "x_train, y_train = data.iloc[:, :-1].values, data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "#___________________________ TRAINING _____________________________________________#\n",
    "\n",
    "\n",
    "# Step 2: Create an instance of backfrontkiller\n",
    "model = backfrontkiller(x_train, y_train, lr=0.01)\n",
    "\n",
    "# Step 3: Train the model\n",
    "model.train(epochs=100)\n",
    "\n",
    "#_____________________________ TESTING _______________________________________#\n",
    "\n",
    "# Step 4: Make predictions on new data\n",
    "new_data = np.random.randn(5, n_features)\n",
    "new_df = pd.DataFrame(new_data, columns=feature_cols)\n",
    "\n",
    "#new_df to numpy array\n",
    "new_df = new_df.to_numpy()\n",
    "\n",
    "predictions = model.predict(new_df)\n",
    "# Step 5: Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = y\n",
    "y_pred = (model.frontProp(x_train) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nModel accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Seqlayer:\n",
    "    def _init_ (self, input_size, num_neurons, activate_func, lr = 0.001):\n",
    "        self.input_size = input_size\n",
    "        self.num_neurons = num_neurons\n",
    "        self.activate_func = activate_func\n",
    "        self.weights = np.random.rand(input_size, num_neurons)\n",
    "        self.bias = np.zeros(num_neurons)\n",
    "        self.lr = lr\n",
    "\n",
    "    def frontProp(self, inputs):\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        return self.sigmoid(weighted_sum)\n",
    "    \n",
    "    def backProp(self, inputs, target, pred):\n",
    "        error = self.mse(target, pred) # mse errror\n",
    "        d_z = self.mse_derivative(target, pred) * self.sigmoid_derivative(pred) # the gradient with respect to the weighted sum before activation\n",
    "        d_weights = self.lr * d_z * inputs #DONT TOUCH THIS!!!\n",
    "        d_bias = self.lr * d_z\n",
    "        self.weights -= d_weights\n",
    "        self.bias -= d_bias\n",
    "        return error\n",
    "    \n",
    "    def train(self, inputs, targets, epochs):\n",
    "        for e in range(epochs):\n",
    "            for i in range(inputs.shape[0]):\n",
    "                input = inputs[i]\n",
    "                target = targets[i]\n",
    "                pred = self.frontProp(inputs)\n",
    "                error = self.backProp(inputs, target, pred)\n",
    "                total_error += error\n",
    "            avg_error = total_error / inputs.shape[0]\n",
    "            print(f\"Epoch {e+1}/{epochs} - Error: {avg_error}\")\n",
    "\n",
    "    def predict(self, features):\n",
    "        return [self.forward(inputs) for inputs in features]\n",
    "    \n",
    "    # Helper functions\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    def mse(self, target, activation):\n",
    "        return np.square(target - activation)\n",
    "    def mse_derivative(self, target, activation):\n",
    "        return 2 * (activation - target) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleNeuralNetwork' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m (X[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m X[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create and train the network\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m nn \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleNeuralNetwork\u001b[49m(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      8\u001b[0m nn\u001b[38;5;241m.\u001b[39mtrain(X, y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimpleNeuralNetwork' is not defined"
     ]
    }
   ],
   "source": [
    "    # Generate some random data\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 2)\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(float).reshape(-1, 1)\n",
    "\n",
    "# Create and train the network\n",
    "nn = SimpleNeuralNetwork(input_size=2, output_size=1, learning_rate=0.1)\n",
    "nn.train(X, y, epochs=1000)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nn.predict(X[:5])\n",
    "print(\"Sample predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
